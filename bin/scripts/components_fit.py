#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jan 13 22:08:54 2021

@author: jan
"""
import numpy as np
from sklearn.mixture import GaussianMixture
import matplotlib as plt
from kneed import KneeLocator

class GmFit:
    
    #Generate gaussian distribution
    def normaldist(self, loc, stdw, size):
        """
        generate normal distribution by numy.random.normal
        
        Parameters
        ----------
        loc : location of the normal distribution (X/Y)
        stdw : standard deviation
        size : size

        Returns
        -------
        ndist : normal distribution 
        """
        
        ndist = np.random.normal(loc, stdw, size)
        
        return (ndist)
    
    #Make intervalls to compare original distribution with generated distribution
    def getIntervalls(self, ndist, rows, columns):
        """
        This Method calculates Intervalls of a distribution. Therefore the size is defined 
        by rows and columns

        Parameters
        ----------
        ndist : Distribution to calculate the intervalls
        rows : Number of rows
        columns : Number of columns

        Returns
        -------
        intervalls : as 2D array

        """
        
        if columns % columns == 0:
            perlabel = columns ** (1/2)
            n_label = int(perlabel)
        else:
            print("n components should not dividable by 2!")
        
        size = rows/perlabel
        intervalls = []
        lowX = 0
        lowY = 0
        
        for x in range(0,n_label):
            highX = lowX + size
            for y in range(0,n_label):
                highY = lowY + size 
                count = 0
            
                for i in ndist:
                    #print(i)
                    if (i[0] <highX and i[0]>lowX) and (i[1] <highY and i[1]>lowY):
                        count += 1
                    # print(i)
            
            # intervall = [low,high,count]
                intervalls.append(count)
                lowY = lowY + size
            lowY = 0
            lowX = lowX + size
        
        return (intervalls)
    
    #EM algorythmus fit gaussian distributions in given distribution
    def emAnalyse(self, distribution, n_cgauss):
        """
        Method to analyse a distribution via EM-algorythm. Therefore Gaussian 
        Mixture Models from sklearn is used.
        

        Parameters
        ----------
        distribution : Distribution to be analyzed (numpy array of float64 vectors)
        n_cgauss : number of gaussian distributions to be fitted (number o components)
        Returns
        -------
        loc : List of locations of the fitted components
        n_stdwX : List of standard deviations of the x-values
        n_stdwY : List of standard deviations of the y-values
        weight : List of the weigts of the fitted components

        """
        
        n_stdwX = []
        n_stdwY = []
        
        gmm = GaussianMixture(n_components=n_cgauss)
        gmm.fit(distribution)
        
        loc = gmm.means_
        covariances = gmm.covariances_
        weight = gmm.weights_
        #print(covariances)
        for i in range(0, (len(covariances))):
            
            dist_matrix = covariances[i]
            stdwX = ((dist_matrix[0])[0]) ** (1/2)
            stdwY = ((dist_matrix[1])[1]) ** (1/2)
            
            n_stdwX.append(stdwX)
            n_stdwY.append(stdwY)
            
        
        return (loc, n_stdwX, n_stdwY, weight)
    
    #Get differences between distributions generated by parameters from Gaussian
    #Mixture Model and original distribution by fitting n components from
    #1 - n_components.
    def getDifference(self, distribution, n_components):
        """
        Method ro calculate the space between a input distribution and genaerated 
        distributiuons. Therefore gaussian distibutions called components, are fit in the original distribution. 
        The parameters of the componets is then used to generate a new distribution.
        The new distribution is then compared with the new distribution. To do that 
        the apce between the original and new distribution is calculated.
        To evaluate the best fit (number of componets) the latter is repeated for 
        n = 0 to n = n_components.
        
        Parameters
        ----------
        distribution : original distribution from ATAC and CHIP data (numpy array of float64 vectors)
        n_components : max number of components to be fit into the original 
                       distribution

        Returns
        -------
        all_diffs : List of all calculated differences

        """
        
        all_diffs =[]
        size = len(distribution)
        
        for z in range(1, n_components+1):
        
            n_loc, n_stdwX, n_stdwY, n_weights = GmFit().emAnalyse(distribution, n_cgauss=z)
            reference_distX = []
            reference_distY = []
        
            for k in range(0, len(n_loc)):
                
                component_size = int(size * (n_weights[k]))
                component_locX = int((n_loc[k])[0])
                component_locY = int((n_loc[k])[1])
                component_stdwX = n_stdwX[k]
                component_stdwY = n_stdwY[k]
                component_distX = GmFit().normaldist(component_locX, component_stdwX, component_size)
                component_distY = GmFit().normaldist(component_locY, component_stdwY, component_size)
                
                reference_distX.extend(component_distX)
                reference_distY.extend(component_distY)
        
            reference_distribution= []
            for i in range(0, len(reference_distX)):
                reference_distribution.append([reference_distX[i],reference_distY[i]])
            
            # GmFit().contourPlot(reference_distribution)
            diff = 0
            ori_intervalls = GmFit().getIntervalls(distribution, 100, 100)
            new_intervalls = GmFit().getIntervalls(reference_distribution, 100, 100)
            
            for j in range(len(ori_intervalls)):
                raw_diff = (ori_intervalls[j])-(new_intervalls[j])
                single_diff = (raw_diff**2)**(1/2)
                diff = diff + single_diff
        
        
            all_diffs.append(diff)
        
        return (all_diffs)
        
    #Evaluate number of components
    def evaluate_by_cutoff(self, all_diffs):
        """
        Evaluate components from calculated differences from 
        method getDifference
        
        Parameters
        ----------
        all_diffs: List of all differences between generated distibutions 
                   and original distribution.

        Returns
        -------
        rates: List of all calculated rates
        count: evaluated number of components
        """
        
        rates = []
        count = 0
        cutoff= 0
        for i in range(0, len(all_diffs)):
            
            rates.append(all_diffs[0]/all_diffs[i])
            
        for j in range(0, len(rates)):
            
            if rates[j]>rates[j+1]:
                cutoff = all_diffs[j]*1.05
                break
            
            else:
                pass
        # print("Cutoff: ")
        # print(cutoff)
        for k in all_diffs:
            count += 1
            if k < cutoff:
                break
        
        return (rates, count)
        
        
    # def evaluate_componets(scores_array, max_components):
        
    #     all_diffs = GmFit().getDifference(scores_array, max_components)
        
    #     x, count = GmFit().evaluate(all_diffs)
        
    #     return (count)
    
    def evaluate(self, all_diffs):
        """
        Evaluate components from calculated differences from 
        method getDifference

        Parameters
        ----------
        all_diffs : Evaluate components from calculated differences from 
        method getDifference

        Returns
        -------
        n : number of components

        """
        x = np.arange(1,(len(all_diffs))+1,1)
        y = all_diffs
        kneedle = KneeLocator(x, y, S=1.0, curve="convex", direction="decreasing")
        
        n = kneedle.knee
        
        return n
        

if __name__ == '__main__':
    """
    Testing the script 
    """
    
    # from TestdataMaker import Testdata_Maker

    n_components = 7
    # #Parameters for the first gaussian distribution:
    # location_ATAC = 50
    # location_CHIP = 50
    # gain_ATAC = 10
    # gain_CHIP = 30
    # size = 5000 
    # rotation = 45
    
    # #Parameters for the second gaussian distribution:
    # secondDistribution = True
    # location_ATAC_2 = 70
    # gain_ATAC_2 = 10
    # location_CHIP_2 = 70
    # gain_CHIP_2 = 10
    # size_2 = 3000  
    # rotation_2 = 0    
    
    # #Parameters for Gaussian Noise:
    # gaussian_Noise = True
    # noise_loop = 50
    # location_ATAC_Noise = 50
    # location_CHIP_Noise = 50
    # standard_deviation_loc_ATAC = 25
    # standard_deviation_loc_CHIP = 25
    # gain_ATAC_Noise = 10
    # gain_CHIP_Noise = 10
    # standard_deviation_gain_ATAC = 1
    # standard_deviation_gain_CHIP = 1
    # size_GaussianNoise = 200
    # standard_deviation_size_GaussianNoise = 100
    
    # #Parameters for linear noise:
    # noise = True
    # size_noise = 1000

    # #Index of the parameter list
    # # 0. loop
    # # 1. location_ATAC
    # # 2. stda_loc_ATAC
    # # 3. gain_ATAC
    # # 4. stda_gain_ATAC
    # # 5. location_CHIP
    # # 6. stda_loc_CHIP
    # # 7. gain_CHIP
    # # 8. stda_gain_CHIP
    # # 9. size
    # # 10.stda_size
    
    # param = []
    # param.append(noise_loop)
    # param.append(location_ATAC_Noise)
    # param.append(standard_deviation_loc_ATAC)
    # param.append(gain_ATAC_Noise)
    # param.append(standard_deviation_gain_ATAC)    
    # param.append(location_CHIP_Noise)
    # param.append(standard_deviation_loc_CHIP)
    # param.append(gain_CHIP_Noise)
    # param.append(standard_deviation_gain_CHIP)
    # param.append(size_GaussianNoise)
    # param.append(standard_deviation_size_GaussianNoise)

    
    # #Testing:
    
    
    # #Execute:
    # scores_array = Testdata_Maker().getScoresArray(location_ATAC, location_CHIP, gain_ATAC, gain_CHIP, size)

    # rotated = Testdata_Maker().rotate(scores_array, location_ATAC, location_CHIP, rotation)  
    # scores_array = rotated
    
    # if secondDistribution:
        
    #     scores_array_2 = Testdata_Maker().getScoresArray(location_ATAC_2, location_CHIP_2, gain_ATAC_2, gain_CHIP_2, size_2)

    #     rotated = Testdata_Maker().rotate(scores_array_2, location_ATAC_2, location_CHIP_2, rotation_2)  
    #     scores_array.extend(rotated)
    
    # if noise:
    #     randomized = Testdata_Maker().randomeNoise(size_noise, scores_array)
    #     scores_array = randomized
    
    # if gaussian_Noise:
    #     g_noise = Testdata_Maker().gaussianNoise(param)
    #     scores_array.extend(g_noise)
     
    # filtered = Testdata_Maker().cutoff(scores_array)
    # distribution = filtered
    
    from interface_scoring import LoadPickle as SC
    
    distribution = SC().loadData(path='/home/jan/python-workspace/angewendete_daten_analyse/testsets/calculated_data_3.pickle')

    all_diffs = GmFit().getDifference(distribution, n_components)
    # k = GmFit().getknee(all_diffs)
    # print("knee: ")
    # print(k)
    count = GmFit().evaluate(all_diffs)
    plt.pyplot.plot(all_diffs)
    dif = np.diff(all_diffs)
    difdif = np.diff(dif)
    print(count)
    #plt.pyplot.plot(all_diffs)
        