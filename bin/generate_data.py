import subprocess
import os
import logging
from datetime import datetime
from scripts.merge_reads import merge_all
from scripts.generate_pickle import parse


class DataConfig:
    """Contains configuration data for the pull_data function.    """

    def __init__(self, genome, biosource, epigenetic_mark):
        self.genome = " ".join(genome)
        self.biosource = " ".join(biosource)
        self.epigenetic_mark = " ".join(epigenetic_mark)
        self.basepath = os.path.abspath(os.path.join(
            os.path.dirname(__file__), os.path.pardir))
        self.logfile = self.setup()

        logging.info(self.genome + " " + self.biosource +
                     " " + self.epigenetic_mark)

    def setup(self):
        """
        Sets up logging and Ensures proper filestructure is given.
        """
        path = os.path.abspath(os.path.join(
            os.path.dirname(__file__), os.path.pardir))
        time = datetime.now().strftime("%d_%m_%Y_%H_%M_%S")

        if not os.path.exists('data/temp'):
            os.makedirs('data/temp')
        if not os.path.exists('results'):
            os.makedirs('results')
        if not os.path.exists('logs'):
            os.makedirs('logs')

        filename = os.path.join(path, "logs", time, "_generate_data.log")
        logging.basicConfig(filename=filename, level=logging.INFO)
        return filename

    def pull_data(self):
        """ Recommended way to use this wrapper. Calls all needed functions.
        """

        self.generate_csv()
        self.download_data()
        self.validate_convert_files()
        self.merge_forward_reversre()
        self.normalize()
        self.sort_files()
        self.generate_dictionaries()

    def generate_csv(self):
        """Ç´enerate a .csv containing all files fitting the parameters.

        Calls csv.r and handles the return value. csv.r uses genomes,
        biosoruces and epigenetic marks to generete a csv of data to be
        downloaded.
        """
        rc = subprocess.call(
            [self.basepath + "/bin/scripts/csv.r", "-b", self.biosource,
             "-g", self.genome,
             "-m", self.epigenetic_mark])
        if rc != 0:
            print("error generating .csv")

    def download_data(self):
        """Download files from .csv

        Calls export_from_csv.r and handles the return value.
        export_from_csv.r takes a csv generated by csv.r and downlaods the listed files into a given directory.

        """
        logging.info("csv: " + self.basepath + "/data/linking_table.csv")
        logging.info("temp: " + self.basepath + "/data/temp")
        rc = subprocess.call([self.basepath + "/bin/scripts/export_from_csv.r", "-i",
                              self.basepath + "/data/linking_table.csv", "-o",
                              self.basepath + "/data/temp"])
        if rc != 0:
            logging.error('Error downloading files:')

    def validate_convert_files(self):
        """ Validates filetypes and converts them to requested filetype if needed

        Calls convert_files.sh and handles return value
        convert_files.sh takes a fileformat and a path with the
        convertable files
        """
        rc = subprocess.call(
            ["bash", self.basepath + "/bin/scripts/convert_files.sh", "bigwig",
             self.basepath + "/data/temp", self.basepath + "/data/chromsizes"])
        if rc != 0:
            print("error converting datafiles ")

    def merge_forward_reversre(self):
        """ merge forward/reverse read files into a single .bw

        Calls scripts.merge_files and handles return value

        """
        filepath = self.basepath + "/data/temp"
        chrompath = self.basepath + "/data/chromsizes"
        merge_all(filepath, chrompath, "stub", "stub")

    def sort_files(self):
        """ merge forward/reverse read files into a single .bw

        Calls scripts.merge_files and handles return value

        """
        rc = subprocess.call(
            ["bash", self.basepath + "/bin/scripts/sort_files.sh",
             self.basepath + "/data/temp/", self.basepath + "/data",
             self.basepath + "/data/linking_table.csv"])
        if rc != 0:
            print("error sorting datafiles")

    def normalize(self):
        """ Normalize files to allow proper analysis

        Calls scripts.normalize and handles return value

        """
        pass

    def generate_dictionaries(self):
        """Generate pickle files for the downloaded data """
        parse()
